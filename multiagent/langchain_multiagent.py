from dotenv import load_dotenv
import os
import math
import json
from langchain.agents import create_react_agent, AgentExecutor
from langchain_openai import ChatOpenAI
from langchain.tools import tool
from langchain import hub
from e2b_code_interpreter import Sandbox

# --- Environment Setup ---
# Purpose: Load API keys and configure LangSmith tracing for debugging.
# Explanation for Manager: Ensures secure access to the LLM (via OpenRouter) and logs agent activity, all configured before sandbox operations.
load_dotenv()
if not os.getenv("OPENROUTER_API_KEY"):
    raise ValueError("OPENROUTER_API_KEY not found")
if not os.getenv("LANGSMITH_API_KEY") and os.getenv("LANGCHAIN_TRACING_V2") == "true":
    raise ValueError("LANGSMITH_API_KEY not found for LangChain tracing")
os.environ["OPENAI_API_KEY"] = os.getenv("OPENROUTER_API_KEY")
os.environ["OPENAI_BASE_URL"] = "https://openrouter.ai/api/v1"
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_API_KEY"] = os.getenv("LANGSMITH_API_KEY")
os.environ["LANGCHAIN_PROJECT"] = os.getenv("LANGSMITH_PROJECT", "LangRouterProject")
print("Environment configured for secure LLM and tracing.")

# --- Language Model ---
# Purpose: Initialize the LLM for agent reasoning to interpret queries and select tools.
# Explanation for Manager: The LLM (LLaMA) powers our agents, but all tool executions are performed securely in the sandbox.
llm = ChatOpenAI(model="meta-llama/llama-3-70b-instruct", temperature=0)
print("LLM initialized for agent reasoning.")

# --- ReAct Prompt ---
# Purpose: Define the reasoning template for agents to select sandboxed tools.
# Explanation for Manager: This template ensures agents choose tools that run in the sandbox, maintaining security.
prompt = hub.pull("hwchase17/react")
print("ReAct prompt loaded from LangChain Hub.")

# --- Sandbox Setup ---
# Purpose: Initialize a single E2B sandbox for all tool executions.
# Explanation for Manager: We use one sandbox to execute all tool operations securely, mimicking Manus AI's isolated environment approach.
sandbox = Sandbox(timeout=300)
print("Initialized single E2B sandbox for all tool executions.")

# --- Helper Function for Output Handling ---
# Purpose: Safely process sandbox output, handling both string and list formats.
# Explanation for Manager: This ensures robust handling of sandbox outputs, preventing errors and logging results for transparency.
def process_sandbox_output(result):
    print(f"Raw sandbox output: stdout={result.logs.stdout}, stderr={result.logs.stderr}")
    if isinstance(result.logs.stdout, list):
        output = "".join(result.logs.stdout).strip()
    else:
        output = result.logs.stdout.strip() if result.logs.stdout else ""
    if not output:
        output = result.logs.stderr or "Error: No output from sandbox."
    return output

# --- Define Tools ---
# All tools execute their logic in the sandbox to ensure security and isolation.
# Explanation for Manager: Each tool runs as Python code in the sandbox, ensuring no local execution, critical for our Manus AI-like system.

@tool
def greet_user(name: str) -> str:
    """Greets a user by name."""
    # Execute greeting logic in the sandbox
    # Explanation for Manager: The greeting is generated by running a Python print statement in the sandbox, ensuring secure execution.
    print(f"Executing greet_user tool in sandbox with name: {name}")
    code = f'print("Hello, \\"{name}\\"! Welcome to LangChain.")'
    result = sandbox.run_code(code)
    output = process_sandbox_output(result)
    print(f"Sandbox output for greet_user: {output}")
    return output

@tool
def reverse_string(text: str) -> str:
    """Reverses a string."""
    # Execute string reversal in the sandbox
    # Explanation for Manager: String reversal is performed in the sandbox, ensuring all text operations are isolated.
    print(f"Executing reverse_string tool in sandbox with text: {text}")
    code = f'print("{text}"[::-1])'
    result = sandbox.run_code(code)
    output = process_sandbox_output(result)
    print(f"Sandbox output for reverse_string: {output}")
    return output

@tool
def mock_weather(city: str) -> str:
    """Returns mock weather info."""
    # Execute weather lookup in the sandbox
    # Explanation for Manager: Weather data is retrieved by running a dictionary lookup in the sandbox, ensuring secure data access.
    print(f"Executing mock_weather tool in sandbox with city: {city}")
    code = f"""
data = {{
    "Hyderabad": "33¬∞C, Sunny",
    "Delhi": "40¬∞C, Dry",
    "Bangalore": "28¬∞C, Cloudy",
    "Chennai": "36¬∞C, Humid"
}}
print(data.get("{city}", "No data for {city}"))
"""
    result = sandbox.run_code(code)
    output = process_sandbox_output(result)
    print(f"Sandbox output for mock_weather: {output}")
    return output

@tool
def safe_calculator(expression: str) -> str:
    """Evaluates math expressions like sqrt(25), log(10)."""
    # Execute math evaluation in the sandbox
    # Explanation for Manager: Math calculations are performed in the sandbox with restricted functions, ensuring secure computation.
    print(f"Executing safe_calculator tool in sandbox with expression: {expression}")
    code = f"""
import math
allowed = {{"sqrt": math.sqrt, "log": math.log, "sin": math.sin, "cos": math.cos, "tan": math.tan}}
try:
    result = eval("{expression}", {{"__builtins__": {{}}}}, allowed)
    print(str(result))
except Exception as e:
    print(f"Error: {{e}}")
"""
    result = sandbox.run_code(code)
    output = process_sandbox_output(result)
    print(f"Sandbox output for safe_calculator: {output}")
    return output

@tool
def run_python_sandbox(code: str) -> str:
    """Executes Python code safely in a sandbox."""
    # Execute user-provided Python code in the sandbox
    # Explanation for Manager: This tool allows custom code execution, fully isolated in the sandbox for security.
    print(f"Executing run_python_sandbox tool in sandbox with code: {code}")
    result = sandbox.run_code(code)
    output = process_sandbox_output(result)
    print(f"Sandbox output for run_python_sandbox: {output}")
    return output

# --- Create Individual Agent Executors ---
# Purpose: Define specialized agents for different tasks, all using sandboxed tools.
# Explanation for Manager: Agents decide which tools to use, but all tool executions occur in the sandbox, ensuring a secure multi-agent system.
text_tools = [greet_user, reverse_string]
math_weather_tools = [mock_weather, safe_calculator]
code_tools = [run_python_sandbox]

text_agent = create_react_agent(llm, text_tools, prompt)
math_agent = create_react_agent(llm, math_weather_tools, prompt)
code_agent = create_react_agent(llm, code_tools, prompt)

text_executor = AgentExecutor(agent=text_agent, tools=text_tools, verbose=True, handle_parsing_errors=True)
math_executor = AgentExecutor(agent=math_agent, tools=math_weather_tools, verbose=True, handle_parsing_errors=True)
code_executor = AgentExecutor(agent=code_agent, tools=code_tools, verbose=True, handle_parsing_errors=True)
print("Initialized agents: All tools executed in single sandbox.")

# --- Routing Logic ---
def route_query(query: str) -> str:
    """Routes query to the appropriate agent based on keywords."""
    # Purpose: Directs user queries to the correct agent, ensuring all tool calls are sandboxed.
    # Explanation for Manager: The router selects the agent, but all subsequent tool operations run in the sandbox for security.
    q = query.lower()
    print(f"Routing query: {query}")
    if any(x in q for x in ["greet", "reverse"]):
        print("Routing to text_executor (all tools use sandbox).")
        return text_executor.invoke({"input": query})["output"]
    if any(x in q for x in ["weather", "temperature", "sqrt", "log", "calculate"]):
        print("Routing to math_executor (all tools use sandbox).")
        return math_executor.invoke({"input": query})["output"]
    if any(x in q for x in ["code", "run", "python"]):
        print("Routing to code_executor (all tools use sandbox).")
        return code_executor.invoke({"input": query})["output"]
    print("Query not recognized (no sandbox used).")
    return "Query not recognized."

# --- Main Test Cases ---
if __name__ == "__main__":
    try:
        # Purpose: Test the multi-agent system with diverse queries, all executed in the sandbox.
        # Explanation for Manager: These tests demonstrate that all operations, from greetings to code execution, are securely sandboxed.
        test_cases = [
            "Greet Saiprakash",
            "Reverse the string 'LangGraph is powerful'",
            "What is the weather in Hyderabad?",
            "Calculate sqrt(81)",
            "Run this code: print('Hello from sandbox!')"
        ]

        for case in test_cases:
            print(f"\nüß† Query: {case}")
            print("‚û°Ô∏è", route_query(case))
    finally:
        # Purpose: Ensure the single sandbox is terminated to free resources.
        # Explanation for Manager: We clean up the sandbox after all operations, ensuring no resource leaks.
        print("\nClosing single E2B sandbox instance...")
        sandbox.kill()